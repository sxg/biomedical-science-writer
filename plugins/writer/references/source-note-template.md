# Source Note Template

Use this template when creating notes for each literature source.

---

# [First Author] et al., [Year]

**Citation**: [Full citation in target format]

**PMID**: [PubMed ID if available]
**DOI**: [DOI if available]
**Type**: [Original Research | Review | Meta-analysis | Case Report | Case Series | Editorial | Letter]

## Key Claims

1. [Main claim relevant to our research question]
2. [Secondary claim]
3. [Additional claim if relevant]

## Methods Summary

[1-2 sentences summarizing methodology — useful for comparing to our approach]

- Study design: [retrospective/prospective/cross-sectional/etc.]
- Sample size: n = [X]
- Key technique: [brief description]

## Key Results

- [Primary outcome: statistic]
- [Secondary outcome: statistic]

## Relevance to Current Study

**Relationship**: [Supports | Contradicts | Provides Context | Methodological Reference]

[2-3 sentences explaining how this source relates to our research question and findings]

## Quotable Phrases

Use sparingly — paraphrase is usually better, but capture uniquely well-phrased statements:

- "[Direct quote]" (p. X)

## For Discussion Section

**Use this source to:**
- [ ] Support our finding that...
- [ ] Contrast with our finding because...
- [ ] Explain mechanism of...
- [ ] Discuss limitation regarding...
- [ ] Suggest future direction about...

## Tags

#[topic1] #[topic2] #[methodology] #[finding-type]

---

## Example Completed Note

# LeCun et al., 2015

**Citation**: LeCun Y, Bengio Y, Hinton G. Deep learning. Nature. 2015;521(7553):436-444. doi:10.1038/nature14539

**PMID**: 26017442
**DOI**: 10.1038/nature14539
**Type**: Review

## Key Claims

1. Deep learning methods can automatically discover representations from raw data
2. Convolutional networks are particularly effective for image and signal processing
3. Recurrent networks capture temporal dependencies in sequential data

## Methods Summary

Comprehensive review of deep learning methods including convolutional neural networks (CNNs) and recurrent neural networks (RNNs), with discussion of training techniques and applications.

- Study design: Review/Tutorial
- Sample size: N/A (review)
- Key technique: Backpropagation, gradient descent, representation learning

## Key Results

- CNNs achieve state-of-the-art in image classification
- RNNs with LSTM units excel at sequence modeling
- Deep learning reduces need for hand-engineered features

## Relevance to Current Study

**Relationship**: Provides Context (foundational paper)

This is a seminal review paper that established the theoretical foundation for deep learning approaches. Our study builds upon these methods for our specific application domain. Cite in Introduction as foundational reference.

## Quotable Phrases

- "representation learning with multiple levels of abstraction" (p. 436)

## For Discussion Section

**Use this source to:**
- [x] Provide context for deep learning methodology
- [ ] Support our finding that...
- [ ] Contrast with our finding because...
- [ ] Explain mechanism of...

## Tags

#deep-learning #neural-networks #foundational #methodology #review
